{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoteBook to Train and Visualize the Features Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing bunch of libraries\n",
    "import os\n",
    "import cv2 as cv\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from itertools import chain\n",
    "from skimage.io import imread, imshow, imread_collection, concatenate_images\n",
    "from skimage.transform import resize\n",
    "from skimage.morphology import label\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "np.random.seed = seed\n",
    "IMG_CHANNELS = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for computing the masks' pixel-to-pixel accuracy, takes as input 2D masks and 2D predictions\n",
    "# (Label 1 corresponds to skin, and 0 to non-skin)\n",
    "# TP - true positive: mask and prediction pixels refer to skin\n",
    "# TN - true negative: mask and prediction pixels refer to non-skin\n",
    "# FP - false positive: mask pixels refer to non-skin, prediction pixels refer to skin\n",
    "# FN - false negative: mask pixels refer to skin, prediction pixels refer to non-skin\n",
    "\n",
    "def acc_comp(msk, preds_test_t):\n",
    "    \n",
    "    mean_acc = np.zeros(1)\n",
    "    mean_TP = np.zeros(1)\n",
    "    mean_TN = np.zeros(1)\n",
    "    mean_FP = np.zeros(1)\n",
    "    mean_FN = np.zeros(1)\n",
    "    \n",
    "    for j in range(msk.shape[0]):\n",
    "        act = msk[j]\n",
    "        pr = preds_test_t[j].reshape(IMG_WIDTH, IMG_HEIGHT)\n",
    "    \n",
    "        c = act == pr \n",
    "        d = act & pr \n",
    "        e = act | pr \n",
    "        neg = act.sum()\n",
    "        pos = (IMG_WIDTH*IMG_HEIGHT)-act.sum()\n",
    "    \n",
    "        TP = round(float(d.sum()),6)\n",
    "        FP = round(float(pr.sum()-d.sum()),6)\n",
    "        TN = round(float((IMG_WIDTH*IMG_HEIGHT)-e.sum()),6)\n",
    "        FN = round(float(e.sum()-pr.sum()),6)\n",
    "        acc = round(float(c.sum())/(IMG_WIDTH*IMG_HEIGHT),6)\n",
    "\n",
    "        mean_TP = np.append([mean_TP],TP)\n",
    "        mean_TN = np.append([mean_TN],TN)\n",
    "        mean_acc = np.append([mean_acc],acc)\n",
    "        mean_FP = np.append([mean_FP],FP)\n",
    "        mean_FN = np.append([mean_FN],FN)\n",
    "    \n",
    "    mean_acc = mean_acc[1:]\n",
    "    mean_TP = mean_TP[1:]\n",
    "    mean_TN = mean_TN[1:]\n",
    "    mean_FP = mean_FP[1:]\n",
    "    mean_FN = mean_FN[1:]\n",
    "    std = round(np.std(mean_acc),6)\n",
    "\n",
    "## Average accuracy for all images    \n",
    "#     avg = round(mean_acc.sum()/msk.shape[0],6) \n",
    "## Average number of true positive pixels (only meaningful if all images have the same shape)\n",
    "#     overall_TP = round(mean_TP.sum()/msk.shape[0],6)\n",
    "## Average number of true negative pixels (only meaningful if all images have the same shape)\n",
    "#     overall_TN = round(mean_TN.sum()/msk.shape[0],6)\n",
    "    \n",
    "    return (mean_acc,std,mean_TP,mean_TN,mean_FP,mean_FN)\n",
    "\n",
    "## Class for extracting time elapsed per training epoch\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "    cb = TimingCallback()\n",
    "    \n",
    "## Intersection-over-Union (IoU) metric, can be tracked instead of the accuracy during training\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the actual implementation of the algorithm starts. You should run everything in order\n",
    "#### A) Get the training data (original images + masks). It is better that the images and masks have the same names. The only thing you need to be concerned with is the sorting of the images. They will be sorted by their names, so you want your original images and corresponding masks to have matching names.  This section adds the original images' path to TRAIN_PATH, and the masks' path to MASK_PATH. You don't have to worry about the naming if you are using our datasets from Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You should replace the paths with the ones corresponding to your machine. Open a terminal, go to the All_Skin_Datasets directory, and type pwd. That would be the path to the datasets folder. If you want to exrtact each dataset individually (recommended), just make sure that TRAIN_PATH and MASK_PATH corresponds to that particular dataset only. And then run the following section. Repeat until all datasets of interest have been extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: HGR\n",
    "TRAIN_PATH1 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset1_HGR/original_images/']\n",
    "MASK_PATH1 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset1_HGR/skin_masks/']\n",
    "train_ids1 = next(os.walk(TRAIN_PATH1[0]))[2]\n",
    "mask_ids1 = next(os.walk(MASK_PATH1[0]))[2]\n",
    "train_ids1.sort()\n",
    "mask_ids1.sort()\n",
    "TRAIN_PATH1 = TRAIN_PATH1*len(train_ids1)\n",
    "MASK_PATH1 = MASK_PATH1*len(train_ids1)\n",
    "\n",
    "# Dataset 2: TDSD\n",
    "TRAIN_PATH5 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset2_TDSD/original_images/']\n",
    "MASK_PATH5 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset2_TDSD/skin_masks/']\n",
    "train_ids5 = next(os.walk(TRAIN_PATH5[0]))[2]\n",
    "mask_ids5 = next(os.walk(MASK_PATH5[0]))[2]\n",
    "train_ids5.sort()\n",
    "mask_ids5.sort()\n",
    "TRAIN_PATH5 = TRAIN_PATH5*len(train_ids5)\n",
    "MASK_PATH5 = MASK_PATH5*len(train_ids5)\n",
    "\n",
    "# Dataset 3: Schmugge\n",
    "TRAIN_PATH6 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset3_Schmugge/original_images/']\n",
    "MASK_PATH6 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset3_Schmugge/skin_masks/']\n",
    "train_ids6 = next(os.walk(TRAIN_PATH6[0]))[2]\n",
    "mask_ids6 = next(os.walk(MASK_PATH6[0]))[2]\n",
    "train_ids6.sort()\n",
    "mask_ids6.sort()\n",
    "TRAIN_PATH6 = TRAIN_PATH6*len(train_ids6)\n",
    "MASK_PATH6 = MASK_PATH6*len(train_ids6)\n",
    "\n",
    "# Dataset 4: Pratheepan\n",
    "TRAIN_PATH2 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset4_Pratheepan/original_images/']\n",
    "MASK_PATH2 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset4_Pratheepan/skin_masks/']\n",
    "train_ids2 = next(os.walk(TRAIN_PATH2[0]))[2]\n",
    "mask_ids2 = next(os.walk(MASK_PATH2[0]))[2]\n",
    "train_ids2.sort()\n",
    "mask_ids2.sort()\n",
    "TRAIN_PATH2 = TRAIN_PATH2*len(train_ids2)\n",
    "MASK_PATH2 = MASK_PATH2*len(train_ids2)\n",
    "\n",
    "# Dataset 5: VDM\n",
    "TRAIN_PATH3 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset5_VDM/original_images/']\n",
    "MASK_PATH3 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset5_VDM/skin_masks/']\n",
    "train_id3 = next(os.walk(TRAIN_PATH3[0]))[2]\n",
    "mask_id3 = next(os.walk(MASK_PATH3[0]))[2]\n",
    "train_id3.sort()\n",
    "mask_id3.sort()\n",
    "train_ids3 = train_id3[1:]\n",
    "mask_ids3 = mask_id3[1:]\n",
    "TRAIN_PATH3 = TRAIN_PATH3*len(train_ids3)\n",
    "MASK_PATH3 = MASK_PATH3*len(train_ids3)\n",
    "\n",
    "# Dataset 6: SFA\n",
    "TRAIN_PATH4 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset6_SFA/original_images/']\n",
    "MASK_PATH4 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset6_SFA/skin_masks/']\n",
    "train_ids4 = next(os.walk(TRAIN_PATH4[0]))[2]\n",
    "mask_ids4 = next(os.walk(MASK_PATH4[0]))[2]\n",
    "train_ids4.sort()\n",
    "mask_ids4.sort()\n",
    "TRAIN_PATH4 = TRAIN_PATH4*len(train_ids4)\n",
    "MASK_PATH4 = MASK_PATH4*len(train_ids4)\n",
    "\n",
    "# Dataset 7: FSD\n",
    "TRAIN_PATH7 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset7_FSD/original_images/']\n",
    "MASK_PATH7 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset7_FSD/skin_masks/']\n",
    "train_ids7 = next(os.walk(TRAIN_PATH7[0]))[2]\n",
    "mask_ids7 = next(os.walk(MASK_PATH7[0]))[2]\n",
    "train_ids7.sort()\n",
    "mask_ids7.sort()\n",
    "TRAIN_PATH7 = TRAIN_PATH7*len(train_ids7)\n",
    "MASK_PATH7 = MASK_PATH7*len(train_ids7)\n",
    "\n",
    "# # Dataset 8: ABDOMEN\n",
    "TRAIN_PATH8 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset8_Abdomen/train/original_images/']\n",
    "MASK_PATH8 = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset8_Abdomen/train/skin_masks/']\n",
    "train_ids8 = next(os.walk(TRAIN_PATH8[0]))[2]\n",
    "mask_ids8 = next(os.walk(MASK_PATH8[0]))[2]\n",
    "train_ids8.sort()\n",
    "mask_ids8.sort()\n",
    "\n",
    "TRAIN_PATH8 = TRAIN_PATH8*len(train_ids8)\n",
    "MASK_PATH8 = MASK_PATH8*len(train_ids8)\n",
    "\n",
    "# Combining all datasets together\n",
    "TRAIN_PATH = np.concatenate((TRAIN_PATH1,TRAIN_PATH2,TRAIN_PATH3,TRAIN_PATH4,TRAIN_PATH5, TRAIN_PATH6,TRAIN_PATH7,TRAIN_PATH8))\n",
    "MASK_PATH = np.concatenate((MASK_PATH1,MASK_PATH2,MASK_PATH3,MASK_PATH4,MASK_PATH5,MASK_PATH6,MASK_PATH7,MASK_PATH8))\n",
    "train_ids = np.concatenate((train_ids1,train_ids2,train_ids3,train_ids4,train_ids5,train_ids6,train_ids7,train_ids8))\n",
    "mask_ids = np.concatenate((mask_ids1,mask_ids2,mask_ids3,mask_ids4,mask_ids5,mask_ids6,mask_ids7,mask_ids8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Extract features and corresponding labels (RUN ONLY ONCE TO GET THE DATA THIS PROCEDURE IS REALLY SLOW). This section extracts the RGB, HSV and YCbCr channels from an image (so a total of 9 features). This procedure does not reshape the images to avoid altering the channels' values in the process.\n",
    "#### Alternatively, you can extract features for each dataset separately, up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print('Getting features and labels from images unreshaped... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "# Initialize the features for the original images\n",
    "path = TRAIN_PATH[0] + train_ids[0]\n",
    "img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "dat = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "hsv = hsv.reshape(img.shape[0]*img.shape[1],3)\n",
    "lab = cv.cvtColor(img, cv.COLOR_RGB2Lab)\n",
    "lab = lab.reshape(img.shape[0]*img.shape[1],3)\n",
    "\n",
    "# Initialize the vector for the labels\n",
    "path = MASK_PATH[0] + mask_ids[0]\n",
    "img = imread(path)\n",
    "# Take the first channel if black and white image has 3 (some masks are like that)\n",
    "if img.ndim == 3:\n",
    "    img = img[:,:,1]   \n",
    "if (np.unique(img).size) > 2:\n",
    "    img = img > 30     # Important, needed to make labels 0's and 1's only \n",
    "else:\n",
    "    img = img > 0\n",
    "L = img.reshape(img.shape[0]*img.shape[1],1)\n",
    "\n",
    "# Features vector with corresponding label\n",
    "dat = np.concatenate((dat,hsv,lab,L),axis=1)\n",
    "\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = TRAIN_PATH[n] + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    b = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "    hsv = hsv.reshape(img.shape[0]*img.shape[1],3)\n",
    "    lab = cv.cvtColor(img, cv.COLOR_RGB2Lab)\n",
    "    lab = lab.reshape(img.shape[0]*img.shape[1],3)\n",
    "    \n",
    "    path = MASK_PATH[n] + mask_ids[n]\n",
    "    img = imread(path)\n",
    "    if img.ndim == 3:\n",
    "        img = img[:,:,1]\n",
    "        \n",
    "    if (np.unique(img).size) > 2:\n",
    "        img = img > 30     # Important, needed to make labels 0's and 1's only \n",
    "    else:\n",
    "        img = img > 0\n",
    "        \n",
    "    L = img.reshape(img.shape[0]*img.shape[1],1)\n",
    "    dat_temp = np.concatenate((b,hsv,lab,L),axis=1)\n",
    "    dat = np.concatenate((dat,dat_temp))\n",
    "\n",
    "# Uncomment the following line if you want to save the data. It will be slow.\n",
    "# np.save(\"data.npy\", dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) If you ran the previous code for separate datasets, you should have saved them under different names. In which case you can load them individually and shuffle the rows of the different features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABD = np.load('ABD.npy')\n",
    "np.random.shuffle(ABD)\n",
    "\n",
    "FSD = np.load('FSD.npy')\n",
    "np.random.shuffle(FSD)\n",
    "\n",
    "HGR = np.load('HGR.npy')\n",
    "np.random.shuffle(HGR)\n",
    "\n",
    "Pratheep = np.load('Pratheep.npy')\n",
    "np.random.shuffle(Pratheep)\n",
    "\n",
    "SCHMG = np.load('SCHMG.npy')\n",
    "np.random.shuffle(SCHMG)\n",
    "\n",
    "SFA = np.load('SFA.npy')\n",
    "np.random.shuffle(SFA)\n",
    "\n",
    "TDSD = np.load('TDSD.npy')\n",
    "np.random.shuffle(TDSD)\n",
    "\n",
    "VDM = np.load('VDM.npy')\n",
    "np.random.shuffle(VDM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Extracting and balancing the data. You can choose the number of features you want to use from each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L=np.where(ABD[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_abd = ABD[K[:]]\n",
    "skin_abd = skin_abd[:30000]\n",
    "L=np.where(ABD[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_abd = ABD[K[:]]\n",
    "noskin_abd = noskin_abd[:70000]\n",
    "\n",
    "L=np.where(FSD[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_fsd = FSD[K[:]]\n",
    "skin_fsd = skin_fsd[:30000]\n",
    "L=np.where(FSD[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_fsd = FSD[K[:]]\n",
    "noskin_fsd = noskin_fsd[:70000]\n",
    "\n",
    "L=np.where(HGR[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_hgr = HGR[K[:]]\n",
    "skin_hgr = skin_hgr[:60000]\n",
    "L=np.where(HGR[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_hgr = HGR[K[:]]\n",
    "noskin_hgr = noskin_hgr[:140000]\n",
    "\n",
    "L=np.where(Pratheep[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_pra = Pratheep[K[:]]\n",
    "skin_pra = skin_pra[:30000]\n",
    "L=np.where(Pratheep[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_pra = Pratheep[K[:]]\n",
    "noskin_pra = noskin_pra[:70000]\n",
    "\n",
    "L=np.where(SCHMG[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_schmg = SCHMG[K[:]]\n",
    "skin_schmg = skin_schmg[:60000]\n",
    "L=np.where(SCHMG[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_schmg = SCHMG[K[:]]\n",
    "noskin_schmg = noskin_schmg[:140000]\n",
    "\n",
    "L=np.where(SFA[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_sfa = SFA[K[:]]\n",
    "skin_sfa = skin_sfa[:60000]\n",
    "L=np.where(SFA[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_sfa = SFA[K[:]]\n",
    "noskin_sfa = noskin_sfa[:140000]\n",
    "\n",
    "L=np.where(TDSD[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_tdsd = TDSD[K[:]]\n",
    "skin_tdsd = skin_tdsd[:60000]\n",
    "L=np.where(TDSD[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_tdsd = TDSD[K[:]]\n",
    "noskin_tdsd = noskin_tdsd[:140000]\n",
    "\n",
    "L=np.where(VDM[:,9] > 0)\n",
    "K = L[0]\n",
    "skin_vdm = VDM[K[:]]\n",
    "skin_vdm = skin_vdm[:60000]\n",
    "L=np.where(VDM[:,9] == 0)\n",
    "K = L[0]\n",
    "noskin_vdm = VDM[K[:]]\n",
    "noskin_vdm = noskin_vdm[:140000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Combine all the features together from different datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to just combine all data together\n",
    "alldata = np.concatenate((ABD,FSD,HGR,VDM,SCHMG,SFA,TDSD,VDM), axis = 0)\n",
    "\n",
    "# If you want to combine the balanced data from the previous section (run either this or the one before)\n",
    "alldata = np.concatenate((skin_abd,skin_hgr,skin_schmg,skin_sfa,skin_tdsd,skin_vdm,noskin_abd,noskin_hgr,noskin_schmg,noskin_sfa,noskin_tdsd,noskin_vdm), axis = 0)\n",
    "\n",
    "np.random.shuffle(alldata)\n",
    "take = alldata[:2000000]\n",
    "print(take.shape)\n",
    "feat = take[:,:9]\n",
    "labels = take[:,9]\n",
    "labels = (labels > 0).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F) Build the Features network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(9, input_dim=9, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(9,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(32,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(64,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(128,)))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(256,)))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(128,)))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(64,)))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(32,)))\n",
    "model.add(Dense(9, activation='relu'))\n",
    "model.add(Dropout(0.2, input_shape=(9,)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "checkpointer = ModelCheckpoint('your_model_name.h5', verbose=1, save_best_only=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "results = model.fit(feat, labels, validation_split=0.2, epochs=50, batch_size=64, shuffle=True, \n",
    "          callbacks=[checkpointer, cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G) Output training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for mean_iou\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Results and Plots\n",
    "# model.summary()\n",
    "print(\"UNET ARCHITECTURE\")\n",
    "print (\"-------------------------------------------------------------\")\n",
    "print(\"Total num of training images: %d\" % len(train_ids))\n",
    "print(\"Max num of epochs: %d\" % 50)\n",
    "print(\"Optimizer: %s\" % 'ADAM')\n",
    "print(\"Batch size: %d\" % 64)\n",
    "print(\"Loss function: %s\" % 'Binary Cross-Entropy')\n",
    "print(\"Validation data percentage: %d\" % 10)\n",
    "print(\"Early stoppping: %s\" % 'Yes')\n",
    "\n",
    "ep = 50;\n",
    "a = results.history[\"acc\"]\n",
    "b = results.history[\"loss\"]\n",
    "c = results.history[\"val_acc\"]\n",
    "d = results.history[\"val_loss\"]\n",
    "e = cb.times\n",
    "print (\"-------------------------------------------------------------\")\n",
    "header = \"#\"+\"    \"+\"Time sec\"+\"      \"+\"Tr_acc\"+\"     \"+\"Tr_loss\"+\"      \"+\"Vl_acc\"+\"     \"+\"Vl_loss\"\n",
    "print(header)\n",
    "print (\"-------------------------------------------------------------\")\n",
    "for l in range(ep):\n",
    "    str = \"%d\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\" % (l, round(e[l],4),round(a[l],4),round(b[l],4),round(c[l],4),d[l])\n",
    "    print (str.expandtabs(2))\n",
    "print (\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H) Evaluate the model on all the images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('your_model_name.h5')\n",
    "\n",
    "ABD_PATH = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset8_Abdomen/test/original_images/']\n",
    "MSK_PATH = ['/Users/lydiazoghbi/Desktop/All_Skin_Datasets/Dataset8_Abdomen/test/skin_masks/']\n",
    "abd_ids = next(os.walk(ABD_PATH[0]))[2]\n",
    "msk_ids = next(os.walk(MSK_PATH[0]))[2]\n",
    "abd_ids.sort()\n",
    "msk_ids.sort()\n",
    "\n",
    "print('Getting features and labels from images unreshaped... ')\n",
    "sys.stdout.flush()\n",
    "\n",
    "path = ABD_PATH[0] + abd_ids[0]\n",
    "img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "dat = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "hsv = hsv.reshape(img.shape[0]*img.shape[1],3)\n",
    "lab = cv.cvtColor(img, cv.COLOR_RGB2Lab)\n",
    "lab = lab.reshape(img.shape[0]*img.shape[1],3)\n",
    "\n",
    "path = MSK_PATH[0] + msk_ids[0]\n",
    "img = imread(path)\n",
    "\n",
    "if img.ndim == 3:\n",
    "    img = img[:,:,1]  \n",
    "img = img > 0\n",
    "img = img.astype(np.uint8)\n",
    "L = img.reshape(img.shape[0]*img.shape[1],1)\n",
    "\n",
    "dat = np.concatenate((dat,hsv,lab,L),axis=1)\n",
    "\n",
    "for n, id_ in tqdm(enumerate(abd_ids), total=len(abd_ids)):\n",
    "    path = ABD_PATH[n] + abd_ids[n]\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    b = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "    hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "    hsv = hsv.reshape(img.shape[0]*img.shape[1],3)\n",
    "    lab = cv.cvtColor(img, cv.COLOR_RGB2Lab)\n",
    "    lab = lab.reshape(img.shape[0]*img.shape[1],3)\n",
    "    \n",
    "    path = MSK_PATH[n] + msk_ids[n]\n",
    "    img = imread(path)\n",
    "\n",
    "    if img.ndim == 3:\n",
    "        img = img[:,:,1]  \n",
    "    img = img > 0\n",
    "    img = img.astype(np.uint8)\n",
    "    L = img.reshape(img.shape[0]*img.shape[1],1)\n",
    "    \n",
    "    dat_temp = np.concatenate((b,hsv,lab,L),axis=1)\n",
    "    dat = np.concatenate((dat,dat_temp))\n",
    "  \n",
    "X = dat[:,0:9]\n",
    "Y = dat[:,9]\n",
    "\n",
    "scores = model.evaluate(X, Y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# Predict using model (kind of a manual evaluation)\n",
    "preds_test = model.predict(X[:int(X.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Find manually true positives and other metrics and save them if needed\n",
    "# answer = acc_comp(Y, preds_test_t)\n",
    "# a = answer[1]\n",
    "# b = answer[2]\n",
    "# c = answer[3]\n",
    "# d = answer[4]\n",
    "\n",
    "# K = np.array((a,b,c,d)).reshape(1,4)\n",
    "# N = np.zeros((1,4))\n",
    "# N = np.concatenate((N,K),axis = 0)\n",
    "# out = N[1:]\n",
    "# j = (out[:,0]+out[:,1])/(out[:,0]+out[:,1]+out[:,2]+out[:,3])\n",
    "# print(np.mean(j))\n",
    "# np.save('features_results.npy',out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) Evaluate the model on ONE image only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('your_model_name.h5')\n",
    "\n",
    "ABD_PATH = ['/home/lalzogbi/Documents/Skin_Datasets/allabdomen/val/skin_val2019/']\n",
    "MSK_PATH = ['/home/lalzogbi/Documents/Skin_Datasets/allabdomen/val/annotations/']\n",
    "abd_ids = next(os.walk(ABD_PATH))[2]\n",
    "msk_ids = next(os.walk(MSK_PATH))[2]\n",
    "abd_ids.sort()\n",
    "msk_ids.sort()\n",
    "\n",
    "# The number 21 is the number of the image you're interested in from the sorted path arrays, make sure it matches the number 21 below\n",
    "path = ABD_PATH + abd_ids[21]\n",
    "img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "b = img.reshape(img.shape[0]*img.shape[1],3)\n",
    "hsv = cv.cvtColor(img, cv.COLOR_RGB2HSV)\n",
    "hsv = hsv.reshape(img.shape[0]*img.shape[1],3)\n",
    "lab = cv.cvtColor(img, cv.COLOR_RGB2Lab)\n",
    "lab = lab.reshape(img.shape[0]*img.shape[1],3)\n",
    "\n",
    "# The number 21 is the number of the image you're interested in from the sorted path arrays\n",
    "path = MSK_PATH + msk_ids[21]\n",
    "img = imread(path)\n",
    "if img.ndim == 3:\n",
    "    img = img[:,:,1]   \n",
    "img = img > 0\n",
    "img = img.astype(np.uint8)\n",
    "L = img.reshape(img.shape[0]*img.shape[1],1)\n",
    "dat_temp = np.concatenate((b,hsv,lab,L),axis=1)\n",
    "\n",
    "X = dat_temp[:,0:9]\n",
    "Y = dat_temp[:,9]\n",
    "    \n",
    "preds_test = model.predict(X[:int(X.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J) Output image results. This is messier if considering testing images of different sizes. Otherwise the img.shape will always be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = np.reshape(preds_test_t,(img.shape[0],img.shape[1]))\n",
    "plt.show()\n",
    "imshow(output)\n",
    "plt.show()\n",
    "imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
