{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoteBook to Optimize the Parameters for the U-Net Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing bunch of libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from keras.layers.core import Dropout, Lambda\n",
    "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras import backend as K\n",
    "from keras.utils import multi_gpu_model\n",
    "from talos.model import lr_normalizer, early_stopper, hidden_layers\n",
    "import talos as ta\n",
    "from keras.optimizers import SGD, Adam, Adadelta, Adagrad, Adamax, RMSprop\n",
    "\n",
    "# Specify image dimensions\n",
    "# Please note that the code may not function as expected for different image size\n",
    "# (It will definitely not run for smaller images)\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='skimage')\n",
    "seed = 42\n",
    "random.seed = seed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Various Function Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function for computing the masks' pixel-to-pixel accuracy, takes as input 2D masks and 2D predictions\n",
    "# (Label 1 corresponds to skin, and 0 to non-skin)\n",
    "# TP - true positive: mask and prediction pixels refer to skin\n",
    "# TN - true negative: mask and prediction pixels refer to non-skin\n",
    "# FP - false positive: mask pixels refer to non-skin, prediction pixels refer to skin\n",
    "# FN - false negative: mask pixels refer to skin, prediction pixels refer to non-skin\n",
    "\n",
    "def acc_comp(msk, preds_test_t):\n",
    "    \n",
    "    mean_acc = np.zeros(1)\n",
    "    mean_TP = np.zeros(1)\n",
    "    mean_TN = np.zeros(1)\n",
    "    mean_FP = np.zeros(1)\n",
    "    mean_FN = np.zeros(1)\n",
    "    \n",
    "    for j in range(msk.shape[0]):\n",
    "        act = msk[j]\n",
    "        pr = preds_test_t[j].reshape(IMG_WIDTH, IMG_HEIGHT)\n",
    "    \n",
    "        c = act == pr \n",
    "        d = act & pr \n",
    "        e = act | pr \n",
    "        neg = act.sum()\n",
    "        pos = (IMG_WIDTH*IMG_HEIGHT)-act.sum()\n",
    "    \n",
    "        TP = round(float(d.sum()),6)\n",
    "        FP = round(float(pr.sum()-d.sum()),6)\n",
    "        TN = round(float((IMG_WIDTH*IMG_HEIGHT)-e.sum()),6)\n",
    "        FN = round(float(e.sum()-pr.sum()),6)\n",
    "        acc = round(float(c.sum())/(IMG_WIDTH*IMG_HEIGHT),6)\n",
    "\n",
    "        mean_TP = np.append([mean_TP],TP)\n",
    "        mean_TN = np.append([mean_TN],TN)\n",
    "        mean_acc = np.append([mean_acc],acc)\n",
    "        mean_FP = np.append([mean_FP],FP)\n",
    "        mean_FN = np.append([mean_FN],FN)\n",
    "    \n",
    "    mean_acc = mean_acc[1:]\n",
    "    mean_TP = mean_TP[1:]\n",
    "    mean_TN = mean_TN[1:]\n",
    "    mean_FP = mean_FP[1:]\n",
    "    mean_FN = mean_FN[1:]\n",
    "    std = round(np.std(mean_acc),6)\n",
    "\n",
    "## Average accuracy for all images    \n",
    "#     avg = round(mean_acc.sum()/msk.shape[0],6) \n",
    "## Average number of true positive pixels (only meaningful if all images have the same shape)\n",
    "#     overall_TP = round(mean_TP.sum()/msk.shape[0],6)\n",
    "## Average number of true negative pixels (only meaningful if all images have the same shape)\n",
    "#     overall_TN = round(mean_TN.sum()/msk.shape[0],6)\n",
    "    \n",
    "    return (mean_acc,std,mean_TP,mean_TN,mean_FP,mean_FN)\n",
    "\n",
    "## Class for extracting time elapsed per training epoch\n",
    "\n",
    "class TimingCallback(Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)\n",
    "\n",
    "    cb = TimingCallback()\n",
    "    \n",
    "## Intersection-over-Union (IoU) metric, can be tracked instead of the accuracy during training\n",
    "\n",
    "def mean_iou(y_true, y_pred):\n",
    "    prec = []\n",
    "    for t in np.arange(0.5, 1.0, 0.05):\n",
    "        y_pred_ = tf.to_int32(y_pred > t)\n",
    "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
    "        K.get_session().run(tf.local_variables_initializer())\n",
    "        with tf.control_dependencies([up_opt]):\n",
    "            score = tf.identity(score)\n",
    "        prec.append(score)\n",
    "    return K.mean(K.stack(prec), axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the actual implementation of the algorithm starts. You should run everything in order\n",
    "#### A) Get the training data (original images + masks). It is better that the images and masks have the same names. The only thing you need to be concerned with is the sorting of the images. They will be sorted by their names, so you want your original images and corresponding masks to have matching names.  This section adds the original images' path to TRAIN_PATH, and the masks' path to MASK_PATH. You don't have to worry about the naming if you are using our datasets from Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You should replace the paths with the ones corresponding to your machine. Open a terminal, go to the All_Skin_Datasets directory, and type pwd. That would be the path to the datasets folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: HGR\n",
    "TRAIN_PATH1 = ['../Input/Skin_Datasets/Dataset1_HGR/original_images/']\n",
    "MASK_PATH1 = ['../Input/Skin_Datasets/Dataset1_HGR/skin_masks/']\n",
    "train_ids1 = next(os.walk(TRAIN_PATH1[0]))[2]\n",
    "mask_ids1 = next(os.walk(MASK_PATH1[0]))[2]\n",
    "train_ids1.sort()\n",
    "mask_ids1.sort()\n",
    "TRAIN_PATH1 = TRAIN_PATH1*len(train_ids1)\n",
    "MASK_PATH1 = MASK_PATH1*len(train_ids1)\n",
    "\n",
    "# Dataset 2: TDSD\n",
    "TRAIN_PATH5 = ['../Input/Skin_Datasets/Dataset2_TDSD/original_images/']\n",
    "MASK_PATH5 = ['../Input/Skin_Datasets/Dataset2_TDSD/skin_masks/']\n",
    "train_ids5 = next(os.walk(TRAIN_PATH5[0]))[2]\n",
    "mask_ids5 = next(os.walk(MASK_PATH5[0]))[2]\n",
    "train_ids5.sort()\n",
    "mask_ids5.sort()\n",
    "TRAIN_PATH5 = TRAIN_PATH5*len(train_ids5)\n",
    "MASK_PATH5 = MASK_PATH5*len(train_ids5)\n",
    "\n",
    "# Dataset 3: Schmugge\n",
    "TRAIN_PATH6 = ['../Input/Skin_Datasets/Dataset3_Schmugge/original_images/']\n",
    "MASK_PATH6 = ['../Input/Skin_Datasets/Dataset3_Schmugge/skin_masks/']\n",
    "train_ids6 = next(os.walk(TRAIN_PATH6[0]))[2]\n",
    "mask_ids6 = next(os.walk(MASK_PATH6[0]))[2]\n",
    "train_ids6.sort()\n",
    "mask_ids6.sort()\n",
    "TRAIN_PATH6 = TRAIN_PATH6*len(train_ids6)\n",
    "MASK_PATH6 = MASK_PATH6*len(train_ids6)\n",
    "\n",
    "# Dataset 4: Pratheepan\n",
    "TRAIN_PATH2 = ['../Input/Skin_Datasets/Dataset4_Pratheepan/original_images/']\n",
    "MASK_PATH2 = ['../Input/Skin_Datasets/Dataset4_Pratheepan/skin_masks/']\n",
    "train_ids2 = next(os.walk(TRAIN_PATH2[0]))[2]\n",
    "mask_ids2 = next(os.walk(MASK_PATH2[0]))[2]\n",
    "train_ids2.sort()\n",
    "mask_ids2.sort()\n",
    "TRAIN_PATH2 = TRAIN_PATH2*len(train_ids2)\n",
    "MASK_PATH2 = MASK_PATH2*len(train_ids2)\n",
    "\n",
    "# Dataset 5: VDM\n",
    "TRAIN_PATH3 = ['../Input/Skin_Datasets/Dataset5_VDM/original_images/']\n",
    "MASK_PATH3 = ['../Input/Skin_Datasets/Dataset5_VDM/skin_masks/']\n",
    "train_id3 = next(os.walk(TRAIN_PATH3[0]))[2]\n",
    "mask_id3 = next(os.walk(MASK_PATH3[0]))[2]\n",
    "train_id3.sort()\n",
    "mask_id3.sort()\n",
    "train_ids3 = train_id3[1:]\n",
    "mask_ids3 = mask_id3[1:]\n",
    "TRAIN_PATH3 = TRAIN_PATH3*len(train_ids3)\n",
    "MASK_PATH3 = MASK_PATH3*len(train_ids3)\n",
    "\n",
    "# Dataset 6: SFA\n",
    "TRAIN_PATH4 = ['../Input/Skin_Datasets/Dataset6_SFA/original_images/']\n",
    "MASK_PATH4 = ['../Input/Skin_Datasets/Dataset6_SFA/skin_masks/']\n",
    "train_ids4 = next(os.walk(TRAIN_PATH4[0]))[2]\n",
    "mask_ids4 = next(os.walk(MASK_PATH4[0]))[2]\n",
    "train_ids4.sort()\n",
    "mask_ids4.sort()\n",
    "TRAIN_PATH4 = TRAIN_PATH4*len(train_ids4)\n",
    "MASK_PATH4 = MASK_PATH4*len(train_ids4)\n",
    "\n",
    "# Dataset 7: FSD\n",
    "TRAIN_PATH7 = ['../Input/Skin_Datasets/Dataset7_FSD/original_images/']\n",
    "MASK_PATH7 = ['../Input/Skin_Datasets/Dataset7_FSD/skin_masks/']\n",
    "train_ids7 = next(os.walk(TRAIN_PATH7[0]))[2]\n",
    "mask_ids7 = next(os.walk(MASK_PATH7[0]))[2]\n",
    "train_ids7.sort()\n",
    "mask_ids7.sort()\n",
    "TRAIN_PATH7 = TRAIN_PATH7*len(train_ids7)\n",
    "MASK_PATH7 = MASK_PATH7*len(train_ids7)\n",
    "\n",
    "# # Dataset 8: ABDOMEN\n",
    "TRAIN_PATH8 = ['../Input/Skin_Datasets/Dataset8_Abdomen/train/original_images/']\n",
    "MASK_PATH8 = ['../Input/Skin_Datasets/Dataset8_Abdomen/train/skin_masks/']\n",
    "train_ids8 = next(os.walk(TRAIN_PATH8[0]))[2]\n",
    "mask_ids8 = next(os.walk(MASK_PATH8[0]))[2]\n",
    "train_ids8.sort()\n",
    "mask_ids8.sort()\n",
    "\n",
    "TRAIN_PATH8 = TRAIN_PATH8*len(train_ids8)\n",
    "MASK_PATH8 = MASK_PATH8*len(train_ids8)\n",
    "\n",
    "# Combine everything\n",
    "TRAIN_PATH = np.concatenate((TRAIN_PATH1,TRAIN_PATH2,TRAIN_PATH3,TRAIN_PATH4,TRAIN_PATH5, TRAIN_PATH6,TRAIN_PATH7,TRAIN_PATH8))\n",
    "MASK_PATH = np.concatenate((MASK_PATH1,MASK_PATH2,MASK_PATH3,MASK_PATH4,MASK_PATH5,MASK_PATH6,MASK_PATH7,MASK_PATH8))\n",
    "train_ids = np.concatenate((train_ids1,train_ids2,train_ids3,train_ids4,train_ids5,train_ids6,train_ids7,train_ids8))\n",
    "mask_ids = np.concatenate((mask_ids1,mask_ids2,mask_ids3,mask_ids4,mask_ids5,mask_ids6,mask_ids7,mask_ids8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Shuffle the data and resize to the dimensions specified in the first block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This creates two array of zeros (for the ground truth and mask data) to store the images in them\n",
    "X_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "Y_train = np.zeros((len(train_ids), IMG_HEIGHT, IMG_WIDTH, 1))\n",
    "print('Getting and resizing train images and masks ... ')\n",
    "sys.stdout.flush()\n",
    "g = list(range(0,len(train_ids)))\n",
    "np.random.shuffle(g)\n",
    "\n",
    "# Creates string arrays to store the path for every training image\n",
    "strs_original = [\"\" for x in range(len(train_ids))]\n",
    "strs_mask = [\"\" for x in range(len(train_ids))]\n",
    "pathmsk = MASK_PATH[0] + mask_ids[0]\n",
    "# Store images path in the corresponding arrays (one array for masks, one for the original ones)\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    strs_mask[n] = MASK_PATH[n] + mask_ids[n]\n",
    "    strs_original[n] = TRAIN_PATH[n] + train_ids[n]\n",
    "\n",
    "# Read images from their paths and store them in arrays\n",
    "for n, id_ in tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "    path = strs_original[g[n]]\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    X_train[n] = img\n",
    "    \n",
    "    path = strs_mask[g[n]]\n",
    "    img = imread(path)\n",
    "    if img.ndim == 3:\n",
    "        img = img[:,:,1]\n",
    "    img = np.expand_dims(resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True), axis=-1)\n",
    "    if (np.unique(img).size) > 2:\n",
    "        # Important, this is needed to convert masks into binary numbers, as some pixels are between 0 and 255\n",
    "        img = img > 30\n",
    "    else:\n",
    "        img = img > 0\n",
    "    Y_train[n] = img      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the data to load easily next time. The saving and loading might actually take more time than just running parts A and B. Your call!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Saving\n",
    "# np.save(\"X_data\",X_train)\n",
    "# np.save(\"Y_data\",Y_train)\n",
    "\n",
    "## Loading\n",
    "# X_train = np.load('./X_data.npy')\n",
    "# Y_train = np.load('./Y_data.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Double check your work! This will output the images and the corresponding masks. Very useful to ensure that the data has been correctly matched. If the images don't match chances are you've messed up the naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ix = random.randint(0, 100)\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Construct the U-Net model, based on the \"U-net:Convolutional networks for biomedical image segmentation\" paper by Ronneberger et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skin_unet_model(X_train,Y_train,X_val,Y_val, params):\n",
    "    IMG_WIDTH = 128\n",
    "    IMG_HEIGHT = 128\n",
    "    IMG_CHANNELS = 3    \n",
    "    inputs = Input((IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS))\n",
    "    s = Lambda(lambda x: x) (inputs)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (s)\n",
    "    c1 = Dropout(0.1) (c1)\n",
    "    c1 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c1)\n",
    "    p1 = MaxPooling2D((2, 2)) (c1)\n",
    "\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p1)\n",
    "    c2 = Dropout(0.1) (c2)\n",
    "    c2 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c2)\n",
    "    p2 = MaxPooling2D((2, 2)) (c2)\n",
    "\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p2)\n",
    "    c3 = Dropout(0.2) (c3)\n",
    "    c3 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c3)\n",
    "    p3 = MaxPooling2D((2, 2)) (c3)\n",
    "\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p3)\n",
    "    c4 = Dropout(0.2) (c4)\n",
    "    c4 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c4)\n",
    "    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
    "\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (p4)\n",
    "    c5 = Dropout(0.3) (c5)\n",
    "    c5 = Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c5)\n",
    "\n",
    "    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n",
    "    u6 = concatenate([u6, c4])\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u6)\n",
    "    c6 = Dropout(0.2) (c6)\n",
    "    c6 = Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c6)\n",
    "\n",
    "    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n",
    "    u7 = concatenate([u7, c3])\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u7)\n",
    "    c7 = Dropout(0.2) (c7)\n",
    "    c7 = Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c7)\n",
    "\n",
    "    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n",
    "    u8 = concatenate([u8, c2])\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u8)\n",
    "    c8 = Dropout(0.1) (c8)\n",
    "    c8 = Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c8)\n",
    "\n",
    "    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n",
    "    u9 = concatenate([u9, c1], axis=3)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (u9)\n",
    "    c9 = Dropout(0.1) (c9)\n",
    "    c9 = Conv2D(16, (3, 3), activation='relu', kernel_initializer='he_normal', padding='same') (c9)\n",
    "\n",
    "    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
    "    \n",
    "    model = Model(inputs=[inputs], outputs=[outputs])\n",
    "    model = multi_gpu_model(model, gpus=4)\n",
    "    model.compile(optimizer=params['optimizer'](lr=lr_normalizer(params['lr'],params['optimizer']))\n",
    "                  ,loss='binary_crossentropy', metrics=['acc'],)\n",
    "    earlystopper = EarlyStopping(patience=40, verbose=1)\n",
    "    checkpointer = ModelCheckpoint('your_model_name.h5', verbose=1, save_best_only=True)\n",
    "    history = model.fit(X_train, Y_train, validation_split=0.20, batch_size=params['batch_size'], epochs=params['epochs'], shuffle=True, \n",
    "                    callbacks=[earlystopper, checkpointer, cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Build the Parameters Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'lr': (0.00001, 0.1,10),\n",
    "     'batch_size': (64, 256, 3),\n",
    "     'epochs': [150],\n",
    "     'dropoutc4': (0.2, 0.6, 5),\n",
    "     'dropoutc6': (0.2, 0.6, 5),\n",
    "     'dropoutc8': (0.2, 0.6, 5),\n",
    "     'optimizer': [Adam, SGD],\n",
    "     }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F) Running the network over the Parameters Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = ta.Scan(x=X_train,\n",
    "            y=Y_train,\n",
    "            model=skin_unet_model,\n",
    "            params=p, debug=True)\n",
    "\n",
    "# from sklearn.model_selection import RandomizedSearchCV\n",
    "# param_grid = {'lr': np.random.uniform(0.00001,0.2,100)}\n",
    "# modeliter = RandomizedSearchCV(estimator=model, param_distributions=param_grid, n_iter=100, cv=10,scoring='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### G) Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "earlystopper = EarlyStopping(patience=30, verbose=1)\n",
    "checkpointer = ModelCheckpoint('attempt1.h5', verbose=1, save_best_only=True)\n",
    "results = modeliter.fit(X_train, Y_train, validation_split=0.20, batch_size=64, epochs=50, shuffle=True, \n",
    "                    callbacks=[earlystopper, checkpointer, cb])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H) Output training results and plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Summarize history for loss\n",
    "plt.plot(results.history['loss'])\n",
    "plt.plot(results.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Summarize history for mean_iou\n",
    "plt.plot(results.history['acc'])\n",
    "plt.plot(results.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# Results and Plots\n",
    "# model.summary()\n",
    "print(\"UNET ARCHITECTURE\")\n",
    "print (\"-------------------------------------------------------------\")\n",
    "print(\"Total num of training images: %d\" % len(train_ids))\n",
    "print(\"Max num of epochs: %d\" % 50)\n",
    "print(\"Optimizer: %s\" % 'ADAM')\n",
    "print(\"Batch size: %d\" % 64)\n",
    "print(\"Loss function: %s\" % 'Binary Cross-Entropy')\n",
    "print(\"Validation data percentage: %d\" % 10)\n",
    "print(\"Early stoppping: %s\" % 'Yes')\n",
    "\n",
    "a = results.history[\"acc\"]\n",
    "b = results.history[\"loss\"]\n",
    "c = results.history[\"val_acc\"]\n",
    "d = results.history[\"val_loss\"]\n",
    "e = cb.times\n",
    "print (\"-------------------------------------------------------------\")\n",
    "header = \"#\"+\"    \"+\"Time sec\"+\"      \"+\"Tr_acc\"+\"     \"+\"Tr_loss\"+\"      \"+\"Vl_acc\"+\"     \"+\"Vl_loss\"\n",
    "print(header)\n",
    "print (\"-------------------------------------------------------------\")\n",
    "for l in range(ep):\n",
    "    str = \"%d\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\\t\\t%f\" % (l, round(e[l],4),round(a[l],4),round(b[l],4),round(c[l],4),d[l])\n",
    "    print (str.expandtabs(2))\n",
    "print (\"-------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) Test against training and validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model = load_model('your_model_name.h5', custom_objects={'mean_iou': mean_iou})\n",
    "# Pedict masks for the training data\n",
    "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.8)], verbose=1)\n",
    "# Predict masks for the validation data\n",
    "preds_val = model.predict(X_train[int(X_train.shape[0]*0.8):], verbose=1)\n",
    "\n",
    "# Threshold out the predictions, turn them into a type that can be shown as an image\n",
    "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
    "preds_val_t = (preds_val > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### J) See predicted masks for training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity check on random training samples\n",
    "ix = random.randint(0, len(preds_train_t))\n",
    "imshow(X_train[ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_train_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K) See predicted masks for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on random validation samples\n",
    "ix = random.randint(0, len(preds_val_t))\n",
    "imshow(X_train[int(X_train.shape[0]*0.7):][ix])\n",
    "plt.show()\n",
    "imshow(np.squeeze(Y_train[int(Y_train.shape[0]*0.7):][ix]))\n",
    "plt.show()\n",
    "imshow(np.squeeze(preds_val_t[ix]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L) Load model, testing data and check against trained network (if masks exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the model for testing, same logic follows for extracting the testing data\n",
    "model = load_model('your_model_name.h5', custom_objects={'mean_iou': mean_iou})\n",
    "ABD_PATH = 'path_to_img_data'\n",
    "MSK_PATH = 'path_to_mask_data'\n",
    "\n",
    "abd_ids = next(os.walk(ABD_PATH))[2]\n",
    "msk_ids = next(os.walk(MSK_PATH))[2]\n",
    "abd_ids.sort()\n",
    "msk_ids.sort()\n",
    "\n",
    "abd = np.zeros((len(abd_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "msk = np.zeros((len(msk_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(abd_ids), total=len(abd_ids)):\n",
    "    path = ABD_PATH + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    abd[n] = img\n",
    "    \n",
    "for n, id_ in tqdm(enumerate(msk_ids), total=len(msk_ids)):\n",
    "    path = MSK_PATH + id_\n",
    "    img = imread(path)\n",
    "    \n",
    "    if img.ndim == 3:\n",
    "        img = img[:,:,1]\n",
    "        \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True)\n",
    "    if (np.unique(img).size) > 2:\n",
    "        img = img > 30           # Important, Needed to make labels 0's and 1's only   \n",
    "    else:   \n",
    "        img = img > 0\n",
    "    img = img.astype(np.uint8)\n",
    "    msk[n] = img\n",
    "    \n",
    "# Actual Predictions\n",
    "preds_test = model.predict(abd[:int(abd.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Overall accuracy on abdomen pictures\n",
    "answer = acc_comp(msk, preds_test_t);\n",
    "\n",
    "# # Save results in a .npy file\n",
    "# a = np.reshape(answer[2],(100,1))\n",
    "# b = np.reshape(answer[3],(100,1))\n",
    "# c = np.reshape(answer[4],(100,1))\n",
    "# d = np.reshape(answer[5],(100,1))\n",
    "# g = np.concatenate([a,b,c,d],axis = 1)\n",
    "# np.save('your_file_name.npy',g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M) Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will output ALL the training results, so be careful\n",
    "for j in range(len(abd_ids)):\n",
    "    print(j)\n",
    "    plt.show()\n",
    "    imshow(abd[j])\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(preds_test_t[j]*255))\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(msk[j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N) Load model, testing data and check against trained network (if masks do NOT exist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model_name.h5', custom_objects={'mean_iou': mean_iou})\n",
    "ABD_PATH = 'path_to_img_data'\n",
    "\n",
    "abd_ids = next(os.walk(ABD_PATH))[2]\n",
    "abd_ids.sort()\n",
    "\n",
    "abd = np.zeros((len(abd_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(abd_ids), total=len(abd_ids)):\n",
    "    path = ABD_PATH + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    abd[n] = img\n",
    "    \n",
    "# Actual Predictions\n",
    "preds_test = model.predict(abd[:int(abd.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### O) Visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in range(len(abd_ids)):\n",
    "    print(j)\n",
    "    plt.show()\n",
    "    imshow(abd[j])\n",
    "    plt.show()\n",
    "    imshow(np.squeeze(preds_test_t[j]*255))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P) Calculate Metrics for Abdomen Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load Data\n",
    "ABD_PATH = '../allabdomen/val/skin_val2019/'\n",
    "MSK_PATH = '../allabdomen/val/annotations/'\n",
    "abd_ids = next(os.walk(ABD_PATH))[2]\n",
    "msk_ids = next(os.walk(MSK_PATH))[2]\n",
    "abd_ids.sort()\n",
    "msk_ids.sort()\n",
    "\n",
    "## Calculating Predictions\n",
    "abd = np.zeros((len(abd_ids), IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS), dtype=np.uint8)\n",
    "msk = np.zeros((len(msk_ids), IMG_HEIGHT, IMG_WIDTH), dtype=np.uint8)\n",
    "\n",
    "sys.stdout.flush()\n",
    "for n, id_ in tqdm(enumerate(abd_ids), total=len(abd_ids)):\n",
    "    path = ABD_PATH + id_\n",
    "    img = imread(path)[:,:,:IMG_CHANNELS]\n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', preserve_range=True)\n",
    "    abd[n] = img\n",
    "    \n",
    "for n, id_ in tqdm(enumerate(msk_ids), total=len(msk_ids)):\n",
    "    path = MSK_PATH + id_\n",
    "    img = imread(path)\n",
    "    \n",
    "    img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant', \n",
    "                                      preserve_range=True)\n",
    "    if (np.unique(img).size) >= 2:\n",
    "        img = img > 30           # Important, Needed to make labels 0's and 1's only   \n",
    "    else:   \n",
    "        img = img > 0\n",
    "    img = img.astype(np.uint8)\n",
    "    msk[n] = img\n",
    "    \n",
    "# Actual Predictions\n",
    "preds_test = model.predict(abd[:int(abd.shape[0])], verbose=1)\n",
    "\n",
    "# Threshold predictions\n",
    "preds_test_t = (preds_test > 0.5).astype(np.uint8)\n",
    "\n",
    "# Calculating Metrics\n",
    "mean_acc = acc_comp(msk, preds_test_t)avg = np.mean(mean_acc)\n",
    "std = np.std(mean_acc)\n",
    "print(\"average \" + str(avg) )\n",
    "print(\"STD \" + str(std) )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
