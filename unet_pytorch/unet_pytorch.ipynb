{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NoteBook to Train and Visualize the U-Net Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing bunch of libraries\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm \n",
    "from skimage.io import imread, imshow\n",
    "from skimage.transform import resize\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\n",
    "from model import UNet\n",
    "import logging\n",
    "\n",
    "seed = 42\n",
    "random.seed = seed\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"Using device: \", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is where the actual implementation of the algorithm starts. You should run everything in order\n",
    "#### A) Get the training data (original images + masks). It is better that the images and masks have the same names. The only thing you need to be concerned with is the sorting of the images. They will be sorted by their names, so you want your original images and corresponding masks to have matching names.  This section adds the original images' path to TRAIN_PATH, and the masks' path to MASK_PATH. You don't have to worry about the naming if you are using our datasets from Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You should replace the paths with the ones corresponding to your machine. Open a terminal, go to the All_Skin_Datasets directory, and type pwd. That would be the path to the datasets folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset 1: HGR\n",
    "TRAIN_PATH1 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset1_HGR/original_images/']\n",
    "MASK_PATH1 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset1_HGR/skin_masks/']\n",
    "train_ids1 = next(os.walk(TRAIN_PATH1[0]))[2]\n",
    "mask_ids1 = next(os.walk(MASK_PATH1[0]))[2]\n",
    "train_ids1.sort()\n",
    "mask_ids1.sort()\n",
    "TRAIN_PATH1 = TRAIN_PATH1*len(train_ids1)\n",
    "MASK_PATH1 = MASK_PATH1*len(train_ids1)\n",
    "\n",
    "# Dataset 2: TDSD\n",
    "TRAIN_PATH5 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset2_TDSD/original_images/']\n",
    "MASK_PATH5 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset2_TDSD/skin_masks/']\n",
    "train_ids5 = next(os.walk(TRAIN_PATH5[0]))[2]\n",
    "mask_ids5 = next(os.walk(MASK_PATH5[0]))[2]\n",
    "train_ids5.sort()\n",
    "mask_ids5.sort()\n",
    "TRAIN_PATH5 = TRAIN_PATH5*len(train_ids5)\n",
    "MASK_PATH5 = MASK_PATH5*len(train_ids5)\n",
    "\n",
    "# Dataset 3: Schmugge\n",
    "TRAIN_PATH6 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset3_Schmugge/original_images/']\n",
    "MASK_PATH6 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset3_Schmugge/skin_masks/']\n",
    "train_ids6 = next(os.walk(TRAIN_PATH6[0]))[2]\n",
    "mask_ids6 = next(os.walk(MASK_PATH6[0]))[2]\n",
    "train_ids6.sort()\n",
    "mask_ids6.sort()\n",
    "TRAIN_PATH6 = TRAIN_PATH6*len(train_ids6)\n",
    "MASK_PATH6 = MASK_PATH6*len(train_ids6)\n",
    "\n",
    "# Dataset 4: Pratheepan\n",
    "TRAIN_PATH2 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset4_Pratheepan/original_images/']\n",
    "MASK_PATH2 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset4_Pratheepan/skin_masks/']\n",
    "train_ids2 = next(os.walk(TRAIN_PATH2[0]))[2]\n",
    "mask_ids2 = next(os.walk(MASK_PATH2[0]))[2]\n",
    "train_ids2.sort()\n",
    "mask_ids2.sort()\n",
    "TRAIN_PATH2 = TRAIN_PATH2*len(train_ids2)\n",
    "MASK_PATH2 = MASK_PATH2*len(train_ids2)\n",
    "\n",
    "# Dataset 5: VDM\n",
    "TRAIN_PATH3 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset5_VDM/original_images/']\n",
    "MASK_PATH3 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset5_VDM/skin_masks/']\n",
    "train_id3 = next(os.walk(TRAIN_PATH3[0]))[2]\n",
    "mask_id3 = next(os.walk(MASK_PATH3[0]))[2]\n",
    "train_id3.sort()\n",
    "mask_id3.sort()\n",
    "train_ids3 = train_id3[1:]\n",
    "mask_ids3 = mask_id3[1:]\n",
    "TRAIN_PATH3 = TRAIN_PATH3*len(train_ids3)\n",
    "MASK_PATH3 = MASK_PATH3*len(train_ids3)\n",
    "\n",
    "# Dataset 6: SFA\n",
    "TRAIN_PATH4 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset6_SFA/original_images/']\n",
    "MASK_PATH4 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset6_SFA/skin_masks/']\n",
    "train_ids4 = next(os.walk(TRAIN_PATH4[0]))[2]\n",
    "mask_ids4 = next(os.walk(MASK_PATH4[0]))[2]\n",
    "train_ids4.sort()\n",
    "mask_ids4.sort()\n",
    "TRAIN_PATH4 = TRAIN_PATH4*len(train_ids4)\n",
    "MASK_PATH4 = MASK_PATH4*len(train_ids4)\n",
    "\n",
    "# Dataset 7: FSD\n",
    "TRAIN_PATH7 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset7_FSD/original_images/']\n",
    "MASK_PATH7 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset7_FSD/skin_masks/']\n",
    "train_ids7 = next(os.walk(TRAIN_PATH7[0]))[2]\n",
    "mask_ids7 = next(os.walk(MASK_PATH7[0]))[2]\n",
    "train_ids7.sort()\n",
    "mask_ids7.sort()\n",
    "TRAIN_PATH7 = TRAIN_PATH7*len(train_ids7)\n",
    "MASK_PATH7 = MASK_PATH7*len(train_ids7)\n",
    "\n",
    "# # Dataset 8: ABDOMEN\n",
    "TRAIN_PATH8 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset8_Abdomen/train/original_images/']\n",
    "MASK_PATH8 = ['/home/anirudh/skin_dataset/All_Skin_Datasets/Dataset8_Abdomen/train/skin_masks/']\n",
    "train_ids8 = next(os.walk(TRAIN_PATH8[0]))[2]\n",
    "mask_ids8 = next(os.walk(MASK_PATH8[0]))[2]\n",
    "train_ids8.sort()\n",
    "mask_ids8.sort()\n",
    "\n",
    "TRAIN_PATH8 = TRAIN_PATH8*len(train_ids8)\n",
    "MASK_PATH8 = MASK_PATH8*len(train_ids8)\n",
    "\n",
    "# Combining all datasets together\n",
    "TRAIN_PATH = np.concatenate((TRAIN_PATH1,TRAIN_PATH2,TRAIN_PATH3,TRAIN_PATH4,TRAIN_PATH5, TRAIN_PATH6,TRAIN_PATH7,TRAIN_PATH8))\n",
    "MASK_PATH = np.concatenate((MASK_PATH1,MASK_PATH2,MASK_PATH3,MASK_PATH4,MASK_PATH5,MASK_PATH6,MASK_PATH7,MASK_PATH8))\n",
    "train_ids = np.concatenate((train_ids1,train_ids2,train_ids3,train_ids4,train_ids5,train_ids6,train_ids7,train_ids8))\n",
    "mask_ids = np.concatenate((mask_ids1,mask_ids2,mask_ids3,mask_ids4,mask_ids5,mask_ids6,mask_ids7,mask_ids8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Parameters to prepare training and test data. \n",
    "# Specify image dimensions\n",
    "IMG_WIDTH = 128\n",
    "IMG_HEIGHT = 128\n",
    "IMG_CHANNELS = 3\n",
    "# Batch size for training. \n",
    "batch_size = 16\n",
    "# Control the size of split of training vs testing. \n",
    "train_to_test_split_ratio = 0.8\n",
    "\n",
    "# Flag to control if data preparation is required. It should be true when running the notebook for the first time or if the image dimensions are changed. \n",
    "prepare_data = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### B) Shuffle the data and resize to the dimensions specified in the first block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if prepare_data:\n",
    "    # This creates two array of zeros (for the ground truth and mask data) to store the images in them. Note the images are \n",
    "    # expected to be in channel foirst format. \n",
    "    images = np.zeros((len(train_ids),IMG_CHANNELS, IMG_HEIGHT, IMG_WIDTH), dtype = np.float)\n",
    "    labels = np.zeros((len(train_ids), 1, IMG_HEIGHT, IMG_WIDTH),dtype = np.float)\n",
    "    print('Getting and resizing train images and masks ... ')\n",
    "    sys.stdout.flush()\n",
    "    g = list(range(0,len(train_ids)))\n",
    "    np.random.shuffle(g)\n",
    "\n",
    "    # Creates string arrays to store the path for every training image\n",
    "    strs_original = [\"\" for x in range(len(train_ids))]\n",
    "    strs_mask = [\"\" for x in range(len(train_ids))]\n",
    "    pathmsk = MASK_PATH[0] + mask_ids[0]\n",
    "    # Store images path in the corresponding arrays (one array for masks, one for the original ones)\n",
    "    for n, id_ in tqdm.tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "        strs_mask[n] = MASK_PATH[n] + mask_ids[n]\n",
    "        strs_original[n] = TRAIN_PATH[n] + train_ids[n]\n",
    "\n",
    "    # Read images from their paths and store them in arrays\n",
    "    for n, id_ in tqdm.tqdm(enumerate(train_ids), total=len(train_ids)):\n",
    "        #  Process image. \n",
    "        path = strs_original[g[n]]\n",
    "        img = np.asarray(imread(path)[:,:,:IMG_CHANNELS])\n",
    "        # Resize the image to fixed dimension. \n",
    "        img = resize(img, (IMG_HEIGHT, IMG_WIDTH), mode='constant')\n",
    "        # Make the image channel first. (NHWC -> NCHW)\n",
    "        img = np.transpose(img, (2, 0, 1))\n",
    "        images[n] = img\n",
    "\n",
    "        #  Process masks. \n",
    "        path = strs_mask[g[n]]\n",
    "        mask = np.asarray(imread(path))\n",
    "        if mask.ndim == 3:\n",
    "            mask = mask[:,:,1]\n",
    "        # Resize the image to fixed dimension. \n",
    "        mask = np.expand_dims(resize(mask, (IMG_HEIGHT, IMG_WIDTH), mode='constant'), axis=-1)\n",
    "        # Make binary lables. \n",
    "        mask = mask > 0\n",
    "        # Make the image channel first. (NHWC -> NCHW)\n",
    "        mask = np.transpose(mask, (2, 0, 1))\n",
    "        labels[n] = mask      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the data to load easily next time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Save and load the images and labels so that you dont have to run the above step everytime. \n",
    "if prepare_data:\n",
    "    print(\"Saved the shuffled images and labels locally.\")\n",
    "    np.save(\"images\",images)\n",
    "    np.save(\"labels\",labels)\n",
    "else:\n",
    "    print(\"Loaded the shuffled images and labels from local path.\")\n",
    "    images = np.load('./images.npy')\n",
    "    labels = np.load('./labels.npy')"
   ]
  },
  {
   "source": [
    "Creating Train and Test DataLoader Object"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the Training and Test dataset.\n",
    "random_state = 1  # To get reproducible results.  \n",
    "images_train, images_test, labels_train, labels_test = train_test_split(images, labels, train_size=train_to_test_split_ratio, random_state=random_state, shuffle = True)\n",
    "\n",
    "# Create tuple pair of training data. \n",
    "train_data = []\n",
    "for i in range(len(images_train)):\n",
    "   train_data.append([images_train[i], labels_train[i]])\n",
    "\n",
    "# Create tuple pair of testing data. \n",
    "test_data = []\n",
    "for i in range(len(images_test)):\n",
    "   test_data.append([images_test[i], labels_test[i]])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "testloader = torch.utils.data.DataLoader(test_data, shuffle=True, batch_size=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### C) Double check your work! This will output the images and the corresponding masks. Very useful to ensure that the data has been correctly matched. If the images don't match chances are you've messed up the naming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the trainloader.\n",
    "images, labels = next(iter(trainloader))\n",
    "print(\"Image Tensor type: \",images.dtype)\n",
    "print(\"Labels Tensor type: \",labels.dtype)\n",
    "image = images[0].numpy()\n",
    "image = np.transpose(image, (1,2,0)) \n",
    "imshow(image)\n",
    "plt.show()\n",
    "label = labels[0].numpy()\n",
    "label = np.transpose(label, (1,2,0)) \n",
    "imshow(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the testloader.\n",
    "images, labels = next(iter(testloader))\n",
    "image = images[0].numpy()\n",
    "image = np.transpose(image, (1,2,0)) \n",
    "imshow(image)\n",
    "plt.show()\n",
    "label = labels[0].numpy()\n",
    "imshow(label[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### D) Construct the Unet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(input_channels=3)\n",
    "model.to(device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E) Fit the model to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "    print(\"Epoch: \", epoch+1)\n",
    "    loss_over_batches = []\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data\n",
    "        inputs = inputs.to(device=device, dtype=torch.float)\n",
    "        labels = labels.to(device=device,dtype=torch.float)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        loss_over_batches.append(loss.item())\n",
    "        if i % 100 == 0:    # print every 100 mini-batches\n",
    "            print(\"Training loss: {}, Batches Processed: {}\".format((np.sum(loss_over_batches) / len(loss_over_batches)),len            (loss_over_batches)))\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model\n",
    "PATH = '../Models/unet_pytorch.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved model for inference. \n",
    "PATH = '../Models/unet_pytorch.pth'\n",
    "model = UNet(input_channels=3)\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### H) See predicted masks for training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Sanity check on random training samples\n",
    "images, labels = next(iter(trainloader))\n",
    "image_arr = images[0].numpy()\n",
    "image_arr = np.transpose(image_arr, (1,2,0)) \n",
    "imshow(image_arr)\n",
    "plt.show()\n",
    "\n",
    "label = labels[0].numpy()\n",
    "imshow(label[0])\n",
    "plt.show()\n",
    "\n",
    "images = images.to(device=device, dtype=torch.float)\n",
    "prediction = model(images)\n",
    "prediction = prediction[0].cpu().detach().numpy()\n",
    "prediction = np.transpose(prediction, (1,2,0)) \n",
    "# prediction = prediction > 0.7\n",
    "imshow(prediction)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I) See predicted masks for validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check on random testing samples\n",
    "images, labels = next(iter(testloader))\n",
    "image_arr = images[0].numpy()\n",
    "image_arr = np.transpose(image_arr, (1,2,0)) \n",
    "imshow(image_arr)\n",
    "plt.show()\n",
    "\n",
    "label = labels[0].numpy()\n",
    "imshow(label[0])\n",
    "plt.show()\n",
    "\n",
    "images = images.to(device=device, dtype=torch.float)\n",
    "prediction = model(images)\n",
    "prediction = prediction[0].cpu().detach().numpy()\n",
    "prediction = np.transpose(prediction, (1,2,0)) \n",
    "# prediction = prediction > 0.7\n",
    "imshow(prediction)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}